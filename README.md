# Gemini File Processor

**Short description:** A lightweight Node.js + Express backend and Next.js frontend that accepts image or PDF uploads, uses Google Gemini (GenAI) to generate product titles and descriptions from images, and summarizes PDFs â€” all processed ephemerally (no persistent storage).

---

## Table of Contents

* [Overview](#overview)
* [Features](#features)
* [Tech stack](#tech-stack)
* [How it works / architecture](#how-it-works--architecture)
* [API endpoints](#api-endpoints)
* [Environment variables](#environment-variables)
* [Local setup & run](#local-setup--run)
* [Production, security & cost notes](#production-security--cost-notes)
* Contributing

---

## Overview

This project provides a minimal, easy-to-run service that:

* Accepts an **image** upload and returns a short **title** and a **description** generated by Google Gemini (GenAI).
* Accepts a **PDF** upload, extracts selectable text with `pdf-parse`, summarizes the content via Gemini, and returns a concise summary.

All uploads are handled in-memory (via `multer` memory storage) and no files are stored to disk or any cloud storage by default.

---

## Features

* Image processing using Gemini vision-capable models
* PDF text extraction using `pdf-parse` and summarization via Gemini
* Strict JSON-only prompts to Gemini to improve parse reliability
* File size limit (default 10MB)
* Minimal dependencies and easy wiring for Next.js frontend

---

## Tech stack

* **Frontend:** Next.js (single-page client component example provided separately)
* **Backend:** Node.js + Express
* **AI SDK:** `@google/genai` (Gemini / Google Generative AI SDK)
* **File parsing:** `multer` (multipart handling), `pdf-parse` (PDF text extraction)
* **Env & utils:** `dotenv`, `cors`, `axios`

**Key npm packages** (example):

```json
express, multer, pdf-parse, @google/genai, dotenv, cors, axios
```

---

## How it works / architecture

1. Frontend sends a `multipart/form-data` POST request with a single field named `file` to the server.
2. The server (Express) validates the upload (type and size) and processes it in-memory.

   * For images: the file buffer is converted to a base64 `inlineData` part and sent to Gemini with a **strict JSON-only** prompt that asks for `{ title, description }`.
   * For PDFs: the buffer is passed to `pdf-parse` to extract selectable text. If text exists, the server chunks long text and sends chunks to Gemini for summarization, optionally combining chunk summaries.
3. The server extracts and sanitizes the JSON returned by Gemini, and responds with a compact JSON object to the client.

```
[Browser/Next.js] --multipart--> [Express API]
       |                                   |
       |                                   +--> [@google/genai (Gemini)]
       |                                   |
       +<----- JSON {title,description}|summary} <---
```

---

## API endpoints

* `POST /api/process-image`

  * Request: `multipart/form-data` with field `file` containing an image
  * Response (200): `{ "title": "...", "description": "..." }`
  * Errors: `400` for invalid input, `413` for file too large, `500` for model/parse errors

* `POST /api/process-pdf`

  * Request: `multipart/form-data` with field `file` containing a PDF
  * Response (200): `{ "summary": "..." }`
  * Errors: `400`/`413`/`422`/`500` depending on issue (no text found, parse failure, etc.)

Notes:

* Field name is `file` (this matches the example frontend `FormData.append('file', file)`).
* The server expects Gemini to return JSON (controllers use strict prompts and also include a JSON-extraction fallback).

---

## Environment variables

Create a `.env` file in your project root with the following keys:

```
GEMINI_API_KEY=YOUR_GEMINI_API_KEY
```

**Important:** How you provide credentials to `@google/genai` may depend on the SDK version and your environment (API key, or Google ADC service account). The controllers in this repository assume you set `GEMINI_API_KEY` and construct the SDK client with that key. If you prefer service account auth, configure `GOOGLE_APPLICATION_CREDENTIALS` accordingly and adapt the client initialization.

---

## Local setup & run

1. Clone the repo:

```bash
git clone https://github.com/imanuelchibuzor/ai-summarizer.git
cd ai-summarizer
```

2. Install dependencies:

```bash
npm install
# or
yarn
```

3. Add `.env` with required vars (see above).

4. Run in development:

```bash
npm run dev
# or
node server.js
```

5. The API will be available at `http://localhost:4000` (or your chosen `PORT`).

---

## Production, security & cost notes

* **Rate limiting:** Add `express-rate-limit` to avoid abuse and runaway AI costs.
* **Authentication:** Protect endpoints with an API key or user auth if you expose them publicly.
* **Content moderation:** Consider scanning returned text for disallowed content before returning to users.
* **Costs:** Generative models charge per token / compute. Monitor usage and set quotas.
* **File validation:** Validate file types and sizes strictly, and scan for potentially malicious files.
* **OCR:** This repo only extracts selectable text from PDFs via `pdf-parse`. For scanned PDFs, integrate Google Vision OCR (recommended) or a server-side PDF->image + tesseract pipeline.

---

## Troubleshooting tips

* If model responses are not valid JSON, use the `STRICT` prompts included in controllers; inspect `geminiRawResponse` during development to iterate on prompts.
* If you get auth errors from `@google/genai`, verify `GEMINI_API_KEY` or your service account setup and the SDK version.
* For very long PDFs, increase chunking logic or tune `CHUNK_SIZE` to fit the model input limits.

---

## Contributing

Contributions are welcome. Open issues for bugs and feature requests.
